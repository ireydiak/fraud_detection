{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset_fname = \"QSAR_dataset.xlsx\"\n",
    "test_fname = \"test_TP1.xlsx\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Représentation des données\n",
    "Dans cette étape, nous devons:\n",
    "- analyser chaque attribut;\n",
    "- proposer un prétraitement des données;\n",
    "- sélectionner les 10 meilleurs attributs avec justification statistique;\n",
    "- visualiser la distribution des 10 meilleurs attributs.\n",
    "\n",
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données d'entraînement\n",
    "df = pd.read_excel(dataset_fname, index_col=0)\n",
    "# Lecture rapide des cinq premières entrées pour valider le chargement adéquat des données\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyser chaque attribut\n",
    "\n",
    "#### Attributs quantitatifs et qualitatifs\n",
    "D'abord, commençons par distinguer les attributs qualitatifs des attributs numériques. Nous portons une attention particulière aux attributs qualitatifs (ou catégoriques) car ceux-ci nécessitent du pré-traitement particulier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(exclude=[\"object\", \"category\"]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=[\"category\", \"object\"]).columns.tolist()\n",
    "print(\"Nombre d'attributs numériques: {}\".format(len(num_cols)))\n",
    "print(\"Nombre d'attributs catégoriques: {}\".format(len(cat_cols)))\n",
    "if len(cat_cols) > 0:\n",
    "    print(cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seul l'attribut `Class` est catégorique, ce qui est normal puisqu'il associe une classe à chacune des observations. Tous nos attributs sont donc numériques, ce qui facilitera grandement notre prétraitement.\n",
    "\n",
    "#### Valeurs aberrantes\n",
    "Maintenant, détectons les valeurs abberantes ou invalides (`NaN`, `±inf`, etc.). Dans notre traitement, nous commençons par convertir les valeurs `±inf` en `NaN` afin d'éviter des duplicata de code. En effet, ces valeurs nécessiteront le même pré-traitement alors une stratégie optimale consiste à les considérer de la même façon dès le départ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace([-np.inf, np.inf], np.nan)\n",
    "nan_cols = df.columns[df.isna().any()]\n",
    "nan_summary = df[nan_cols].isna().sum().sort_values(ascending=False)\n",
    "nan_ratio = nan_summary / len(df)\n",
    "nan_df = pd.concat((nan_summary, nan_ratio), axis=1)\n",
    "nan_df = nan_df.rename(columns={0: \"Count\", 1: \"Ratio\"})\n",
    "print(nan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que les variables `vsurf_V` et `vsurf_S` contiennent beaucoup de valeurs NaN (11.69% et 8.44% respectivement). Par contraste, `ASA+`, `ASA-`, `a_heavy` et `a_IC` contiennent seulement entre 1 et 2 observations invalides. Plus tard, nous pourrons probablement les supprimer sans affecter grandement la distribution des données.\n",
    "\n",
    "#### Valeurs uniques\n",
    "Finalement, nous devons considérons les valeurs uniques. Celles-ci ne sont pas techniquement invalides, mais peuvent néamoins être ignorées car elles ne contribueront pas à la décision des algorithmes. En effet, puisque ces attributs prennent une seule valeur distincte, elles ne seront pas déterminantes dans la tâche de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_cols = df.columns[df.nunique() == 1]\n",
    "uniq_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les attributs possèdent donc plusieurs valeurs distinctes.\n",
    "\n",
    "#### Analyse statistique\n",
    "On peut maintenant extraire certaines statistiques de base pour tous les attributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_describe = df.describe()\n",
    "df_describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On normalise les différentes variances en fonction de leur moyenne respective. Ceci permet d'évaluer le degré de dispersion des différents attributs sous une même échelle. Des grandes moyennes vont naturellement générées de grandes variances mais cela n'implique pas nécessairement que les données sont très dispersées; l'échelle de mesure est simplement grande. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_std = df_describe.loc[[\"std\"]].to_numpy()\n",
    "np_mean = df_describe.loc[[\"mean\"]].to_numpy()\n",
    "normalized_std = np_std / np.abs(np_mean)\n",
    "normalized_describe = df_describe.copy()\n",
    "normalized_describe.loc[[\"std\"]] = normalized_std\n",
    "normalized_describe.sort_values(by=\"std\", ascending=False, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate une très grande variance au niveau de `vsurf_R` et une variance presque nulle pour `VAdjMa`. On peut donc déjà indiqué que `VAdjMa` présente une distribution centrée autour de sa moyenne que `vsurf_R` sera très dispersée. On peut s'en convaincre par une visualisation. Cette dernière variable est donc plus \"bruitée\" mais en même temps contient plus d'information que la première. Ce constat pourrait être utile lors de la sélection des attributs plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.scatterplot(x=df[\"VAdjMa\"], y=df[\"VAdjMa\"], hue=df[\"Class\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse de la covariance\n",
    "On peut maintenant évaluer la matrice de variance-covariance entre les attributs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code inspiré de https://seaborn.pydata.org/examples/many_pairwise_correlations.html\n",
    "# Pour éviter de la confusion, on calcule la matrice de covariance absolue.\n",
    "# Ainsi, les cases bleues indiquent une absence de corrélation et les cases rouges l'inverse.\n",
    "corr_mat = df[num_cols].corr().abs()\n",
    "# On masque le haut de la matrice diagonale\n",
    "mask = np.triu(np.ones_like(corr_mat, dtype=bool))\n",
    "f, ax = plt.subplots(figsize=(30, 20))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(corr_mat, annot=False, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code inspiré de https://chrisalbon.com/code/machine_learning/feature_selection/drop_highly_correlated_features/\n",
    "# Nous avons testé plusieurs ratio différents et celui-ci permettait de filtrer plusieurs attributs.\n",
    "max_rho = 0.75\n",
    "# Sélectionner triangle supérieur de la matrice de corrélation\n",
    "upper = corr_mat.where(np.triu(np.ones_like(corr_mat), k=1).astype(bool))\n",
    "# Sélectionner les attributs dont la corrélation dépasse le seuil `max_rho`\n",
    "to_drop = [column for column in upper.columns if any(upper[column] >= max_rho)]\n",
    "print(\"Total d'attributs dépassant le seuil {:.2f}: {}\".format(max_rho, len(to_drop)))\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prime = df.drop(columns=to_drop, inplace=False)\n",
    "print(\"Nombre d'attributs supprimés: {}\".format(len(to_drop)))\n",
    "print(\"Ratio : {:8.4f}\".format(len(to_drop) / len(df)))\n",
    "print(\"Nombre d'attributs restants: {}\".format(len(df_prime.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_prime = df_prime.select_dtypes(exclude=[\"object\", \"category\"]).columns.tolist()\n",
    "corr_mat_prime = df_prime[num_cols_prime].corr().abs()\n",
    "# On masque le haut de la matrice diagonale\n",
    "f, ax = plt.subplots(figsize=(30, 20))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(corr_mat_prime, annot=False, cmap=cmap)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c0a2db9f4e0e47d22f4e0c743aa4281b46621878462a1b3449ca0fca22b1eb0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
