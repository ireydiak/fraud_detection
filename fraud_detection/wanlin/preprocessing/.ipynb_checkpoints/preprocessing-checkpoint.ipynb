{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec80697-8418-46a7-8f68-812a05adc914",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import seaborn as sns  # data visualization library  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee459967-c73e-4b92-bfc4-d33682cff6ac",
   "metadata": {},
   "source": [
    "## Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dd0f461-27f4-4cc3-ac28-222151fa8fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './'\n",
    "train_identity = pd.read_csv(f'{folder_path}train_identity.csv')\n",
    "train_transaction = pd.read_csv(f'{folder_path}train_transaction.csv')\n",
    "test_identity = pd.read_csv(f'{folder_path}test_identity.csv')\n",
    "test_transaction = pd.read_csv(f'{folder_path}test_transaction.csv')\n",
    "sub = pd.read_csv(f'{folder_path}sample_submission.csv')\n",
    "# let's combine the data and work with the whole dataset\n",
    "train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
    "test = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e746f97-33e5-46a3-8c1d-23e6947ee5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset has 590540 rows and 434 columns.\n",
      "Test dataset has 506691 rows and 433 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f'Train dataset has {train.shape[0]} rows and {train.shape[1]} columns.')\n",
    "print(f'Test dataset has {test.shape[0]} rows and {test.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a7d60d-971b-42b5-969b-361d7f528d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete useless variables\n",
    "del train_identity, train_transaction, test_identity, test_transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ebd048-0ca9-42dc-afc9-8dd50c0fee33",
   "metadata": {},
   "source": [
    "## Drop the columns with 85% or more null values\n",
    "The transaction table has more cases of missing data. 55 of the 394 features have more than 80% missing data, and 113 features have missing data between 70% and 80%. Similar missing data patterns were found among features which have consecutive names. Specifically, the missing data rates of \"D6\"-\"D9\" and \"D12\"-\"D14\" were all above 87.3122%. The missing data rate of \"D6\" - \"D9\" and \"D12\" - \"D14\" was above 87.3122%. The missing data rate for \"V138\" - \"V166\" is between 86.1227% and 86.1237%. All features from \"V323\" to \"V339\" have missing data rate of 86.054967%. This regularity exhibited in the missing data suggests that there may have a strong correlation between these consecutive numerically arranged features, although the data provider does not explain the specific meaning expressed by these encrypted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6c6f3c-6463-45b7-879f-df984676e512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_drop_89:  ['D6', 'D7', 'D8', 'D9', 'D12', 'D13', 'D14']\n",
      "list_drop_86:  ['V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166']\n",
      "list_drop_85:  ['V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339']\n"
     ]
    }
   ],
   "source": [
    "list_drop_89 = []\n",
    "for i in list(range(6,10)):\n",
    "    add =\"D\" + str(i)\n",
    "    #print(add)\n",
    "    list_drop_89.append(add)\n",
    "for i in list(range(12,15)):\n",
    "    add =\"D\" + str(i)\n",
    "    #print(add)\n",
    "    list_drop_89.append(add)\n",
    "print(\"list_drop_89: \",list_drop_89)\n",
    "\n",
    "list_drop_86 = []\n",
    "for i in list(range(138,167)):\n",
    "    add =\"V\" + str(i) \n",
    "    #print(add)\n",
    "    list_drop_86.append(add)\n",
    "print(\"list_drop_86: \",list_drop_86)\n",
    "\n",
    "list_drop_85 = []\n",
    "for i in list(range(323,340)):\n",
    "    add =\"V\" + str(i) \n",
    "    #print(add)\n",
    "    list_drop_85.append(add)\n",
    "print(\"list_drop_85: \",list_drop_85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5ffef-3179-48ea-99dc-f29f3d972657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8150127-67e4-49b5-a68c-6fd2e5a4cf4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b4570-3653-4da5-9dab-bc821fa494e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b912c4-373e-4e66-ac32-ab12a48e1275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9a1051e-004f-4514-9edb-03a67da207c0",
   "metadata": {},
   "source": [
    "References: \n",
    "https://www.kaggle.com/code/artgor/eda-and-models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
